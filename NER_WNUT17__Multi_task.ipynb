{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER-WNUT17_ Multi task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSXUbO_5H3qJ",
        "outputId": "ec0ed2c0-ca0f-49dc-9ec8-81cee4bf8d6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvJvCwO3i70U"
      },
      "source": [
        "**Single Task approach**:\n",
        "\n",
        "Experimental Settings:       \n",
        "Twitter word settings:\n",
        "\n",
        "* window = 3 tokens\n",
        "* embeddings -> twitter pre-trained embeddings, Godin\n",
        "* dimensions = 400\n",
        "* LSTM units = 100 -> 200 (Bi-LSTM)\n",
        "\n",
        "Other settings:\n",
        "\n",
        "* Epochs -> 150\n",
        "* Batch size -> 500\n",
        "* Optimizer -> Admax\n",
        "* Seed 1337 for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrJxHpeQj9qs",
        "outputId": "0b7545fd-43bd-4397-ae49-d432a32565c7"
      },
      "source": [
        "# Install required packages\n",
        "!pip install python-crfsuite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-crfsuite\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 184 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 245 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 266 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 276 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 286 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 296 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 481 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 491 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 501 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 522 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 532 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 542 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 552 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 563 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 573 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 583 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 593 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 716 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 727 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 737 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 743 kB 6.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXy3pTXYpeub"
      },
      "source": [
        "### Download the Word2vec model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdL4qEW0poSo"
      },
      "source": [
        "https://github.com/FredericGodin/TwitterEmbeddings     \n",
        "https://drive.google.com/file/d/1lw5Hr6Xw0G0bMT1ZllrtMqEgCTrM7dzc/view"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDUjign4_7ur"
      },
      "source": [
        "# Change path to NER-WNUT17\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/NER-WNUT17/NER-WNUT17')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoKQCiZliW7n"
      },
      "source": [
        "experiment = 'notebook'\n",
        "\n",
        "# os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cuda,floatX=float64\"\n",
        "import sys\n",
        "sys.path += [new_path \n",
        "             for new_path in ['..', \n",
        "                              '../embeddings/twitter'] \n",
        "             if new_path not in sys.path]\n",
        "\n",
        "import numpy as np\n",
        "seed_number = 1337\n",
        "np.random.seed(seed_number)  # for reproducibility\n",
        "\n",
        "import pycrfsuite as crf\n",
        "import matplotlib.pyplot as plt\n",
        "import common.utilities as utils\n",
        "\n",
        "from settings import *\n",
        "from pycrfsuite import ItemSequence\n",
        "from collections import Counter, defaultdict as ddict\n",
        "from embeddings.twitter.word2vecReader import Word2Vec, Vocab\n",
        "from sklearn.metrics import confusion_matrix, classification_report   \n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.pooling import GlobalAveragePooling1D\n",
        "from keras.optimizers import Adamax\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.initializers import RandomUniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT6axnxplKJR"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmShPqJAj5WB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee3efe8-233f-4b05-c5ee-d965ae1a9383"
      },
      "source": [
        "tweets_train, labels_train = utils.read_file_as_lists(TRAIN_PREPROC_URL)\n",
        "tweets_dev,   labels_dev   = utils.read_file_as_lists(DEV_PREPROC_URL)\n",
        "tweets_test,  labels_test  = utils.read_file_as_lists(TEST_PREPROC_URL)\n",
        "\n",
        "tweets_train += tweets_dev\n",
        "labels_train += labels_dev\n",
        "\n",
        "vocabulary = list(set(utils.flatten(tweets_train + tweets_test)))\n",
        "\n",
        "print(\"Vocabulary:\", len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary: 19329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khgaevYGlXbn"
      },
      "source": [
        "### Loading POS Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tylw_UdKlSBP"
      },
      "source": [
        "pos_tweets_train, postags_train = utils.read_file_as_lists(TRAIN_PREPROC_URL_POSTAG)\n",
        "pos_tweets_dev,   postags_dev   = utils.read_file_as_lists(DEV_PREPROC_URL_POSTAG)\n",
        "pos_tweets_test,  postags_test  = utils.read_file_as_lists(TEST_PREPROC_URL_POSTAG)\n",
        "\n",
        "pos_tweets_train += pos_tweets_dev\n",
        "postags_train += postags_dev\n",
        "\n",
        "utils.sync_postags_and_tweets(tweets_train, pos_tweets_train, postags_train) \n",
        "utils.sync_postags_and_tweets(tweets_test, pos_tweets_test, postags_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTGBknS4mAoO"
      },
      "source": [
        "### Loading Twitter embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws8yZYFYlfMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fae7e1-eab8-4bcd-a9cb-decbde440bbc"
      },
      "source": [
        "%%time \n",
        "w2v_model = Word2Vec.load_word2vec_format(W2V_TWITTER_EMB_GODIN, binary=True)\n",
        "twitter_vb = {token:v.index for token,v in w2v_model.vocab.items()}\n",
        "\n",
        "# Using only needed embeddings (faster this way)\n",
        "twitter_index2word, twitter_embeddings = utils.pick_embeddings_by_indexes(vocabulary, w2v_model.syn0, twitter_vb)\n",
        "twitter_index2word = [PAD_TOKEN, UNK_TOKEN] + twitter_index2word\n",
        "twitter_word2index = ddict(lambda: twitter_index2word.index(UNK_TOKEN), {w:i for i,w in enumerate(twitter_index2word)})\n",
        "twitter_embeddings = np.append(np.zeros((2,twitter_embeddings.shape[1])), twitter_embeddings, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 7s, sys: 6.83 s, total: 1min 13s\n",
            "Wall time: 2min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnI2-TefGwbw"
      },
      "source": [
        "### Loading Gazetteers embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8H5WEjeG2Jb"
      },
      "source": [
        "gazetteers = utils.read_file_as_list_of_tuples(GAZET_EMB_ONE_CHECK)[0]\n",
        "index2gaze, gaze_embeddings = zip(*[(data[0], data[1:]) for data in gazetteers])\n",
        "\n",
        "index2gaze = [UNK_TOKEN, PAD_TOKEN] + list(index2gaze)\n",
        "gaze2index = ddict(lambda: index2gaze.index(UNK_TOKEN), {g:i for i,g in enumerate(index2gaze)})\n",
        "gaze_embeddings = np.append(np.zeros((2,6)), gaze_embeddings, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XzOTJ6bBo-Z"
      },
      "source": [
        "### Encoding words and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS_wkm30nNGx"
      },
      "source": [
        "window = 1\n",
        "\n",
        "x_word_twitter_train = utils.build_x_matrix(window, [[twitter_word2index[token] for token in tweet] for tweet in tweets_train], twitter_word2index[PAD_TOKEN])\n",
        "x_word_twitter_test  = utils.build_x_matrix(window, [[twitter_word2index[token] for token in tweet] for tweet in tweets_test], twitter_word2index[PAD_TOKEN])\n",
        "\n",
        "index2label_cat = [\n",
        "    'B-corporation',\n",
        "    'B-creative-work',\n",
        "    'B-group',\n",
        "    'B-location',\n",
        "    'B-person',\n",
        "    'B-product',\n",
        "    'I-corporation',\n",
        "    'I-creative-work',\n",
        "    'I-group',\n",
        "    'I-location',\n",
        "    'I-person',\n",
        "    'I-product',\n",
        "    'O'\n",
        "]\n",
        "\n",
        "y_cat_train, label2index_cat, _ = utils.vectorize_labels(labels_train, index2label_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71OibR4SBu_U"
      },
      "source": [
        "def map_to_binary(labels):\n",
        "    return [['TRUE' if label != 'O' else 'FALSE' for label in lbls] for lbls in labels]\n",
        "    \n",
        "labels_seg_train = map_to_binary(labels_train)\n",
        "\n",
        "index2label_seg = ['FALSE', 'TRUE']\n",
        "label2index_seg = { l:i for i, l in enumerate(index2label_seg) }\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_seg_train = lb.fit_transform(utils.flatten(labels_seg_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlE5FwGjB3nh"
      },
      "source": [
        "### Encoding POS tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r3qGodqBzqY"
      },
      "source": [
        "index2postag = [PAD_TOKEN] + list(set(utils.flatten(postags_train + postags_test)))\n",
        "postag2index = {w:i for i,w in enumerate(index2postag)}\n",
        "\n",
        "x_postag_train = utils.build_x_matrix(window, [[postag2index[token] for token in tweet] for tweet in postags_train], postag2index[PAD_TOKEN])\n",
        "x_postag_test  = utils.build_x_matrix(window, [[postag2index[token] for token in tweet] for tweet in postags_test], postag2index[PAD_TOKEN])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV84Onr0HyYb"
      },
      "source": [
        "### Encoding orthography"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWREWI2KH3dh"
      },
      "source": [
        "ortho_max_length = 20\n",
        "\n",
        "index2ortho = ['x', 'c', 'C', 'n', 'p']\n",
        "ortho2index = ddict(lambda: 0, {o:i for i,o in enumerate(index2ortho)})\n",
        "\n",
        "x_ortho_twitter_train = pad_sequences(utils.encode_tokens(ortho2index, utils.flatten(utils.orthographic_mapping(tweets_train))), maxlen=ortho_max_length)\n",
        "x_ortho_twitter_test  = pad_sequences(utils.encode_tokens(ortho2index, utils.flatten(utils.orthographic_mapping(tweets_test))), maxlen=ortho_max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mybhSaKIISlr"
      },
      "source": [
        "### Encoding gazetteers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NebxT-F5IXCz"
      },
      "source": [
        "encoded_gaze_train = [[gaze2index[token] for token in tweet] for tweet in tweets_train]\n",
        "encoded_gaze_test  = [[gaze2index[token] for token in tweet] for tweet in tweets_test]\n",
        "\n",
        "x_gaze_train = utils.build_x_matrix(window, encoded_gaze_train, gaze2index[PAD_TOKEN])\n",
        "x_gaze_test  = utils.build_x_matrix(window, encoded_gaze_test, gaze2index[PAD_TOKEN])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0_h0n8pI1bt"
      },
      "source": [
        "### Neural Network -- Character Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDVwcOxfI8KA"
      },
      "source": [
        "def get_input_layer(shape, name):\n",
        "    return Input(shape=shape, dtype='int32', name='{}_input'.format(name))\n",
        "\n",
        "def pretrained_embedding_layer(embeddings, input_layer, input_len, name):\n",
        "    embed_layer = Embedding(embeddings.shape[0], \n",
        "                           embeddings.shape[1], \n",
        "                           input_length=input_len, \n",
        "                           weights=[embeddings],\n",
        "                           trainable=False,\n",
        "                           name='{}_embed'.format(name))(input_layer)\n",
        "    embed_layer = Dropout(0.5, name='{}_embed_dropout'.format(name))(embed_layer)\n",
        "    return embed_layer\n",
        "    \n",
        "    \n",
        "def rand_uniform_embedding_layer(input_layer, input_dim, output_dim, input_len, name):\n",
        "    uniform = RandomUniform(seed=seed_number, \n",
        "                            minval=-np.sqrt(3/output_dim),  # Suggested by\n",
        "                            maxval= np.sqrt(3/output_dim))  # He et al (2015) \n",
        "    embed_layer = Embedding(input_dim=input_dim, \n",
        "                            output_dim=output_dim,\n",
        "                            input_length=input_len, \n",
        "                            embeddings_initializer=uniform,\n",
        "                            trainable=False,\n",
        "                            name='{}_embed'.format(name))(input_layer)\n",
        "    embed_layer = Dropout(0.5, name='{}_embed_dropout'.format(name))(embed_layer)\n",
        "    return embed_layer\n",
        "\n",
        "ortho_dim = 30\n",
        "char_ortho_input = get_input_layer((ortho_max_length,), 'char_ortho')\n",
        "char_ortho_embed = rand_uniform_embedding_layer(char_ortho_input, \n",
        "                                                len(index2ortho), \n",
        "                                                ortho_dim, \n",
        "                                                ortho_max_length, \n",
        "                                                'char_ortho')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wndO9X-kJGoM"
      },
      "source": [
        "### CNN Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyhnh0f1JIZR"
      },
      "source": [
        "def get_char_cnn(embedded, name, filters=64, kernel_size=3, dense_units=32, convs=2):\n",
        "    conv_net = embedded\n",
        "    for _ in range(convs):\n",
        "        conv_net = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(conv_net)\n",
        "    conv_net = GlobalAveragePooling1D()(conv_net)\n",
        "    conv_net = Dense(dense_units, activation='relu', name='{}_dense'.format(name))(conv_net)\n",
        "    return conv_net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBSXk5crJent",
        "outputId": "35602ec1-c564-47fe-9a16-95a146b16685"
      },
      "source": [
        "\n",
        "char_encoded = char_ortho_embed\n",
        "\n",
        "char_encoded = get_char_cnn(char_encoded, 'char_encoded')\n",
        "char_encoder = Model(inputs=[char_ortho_input], outputs=[char_encoded])\n",
        "char_encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "char_ortho_input (InputLayer [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "char_ortho_embed (Embedding) (None, 20, 30)            150       \n",
            "_________________________________________________________________\n",
            "char_ortho_embed_dropout (Dr (None, 20, 30)            0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 18, 64)            5824      \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 16, 64)            12352     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "char_encoded_dense (Dense)   (None, 32)                2080      \n",
            "=================================================================\n",
            "Total params: 20,406\n",
            "Trainable params: 20,256\n",
            "Non-trainable params: 150\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1vfc0HOCHjn"
      },
      "source": [
        "### Neural network- Word representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3fBdAJdChVH"
      },
      "source": [
        "twitter_input = get_input_layer((window*2+1,), 'word_twitter')\n",
        "twitter_embed = pretrained_embedding_layer(twitter_embeddings, \n",
        "                                           twitter_input, \n",
        "                                           window*2+1, \n",
        "                                           'word_twitter')\n",
        "\n",
        "postag_dim = 100\n",
        "postag_input = get_input_layer((window*2+1,), 'word_postag')\n",
        "postag_embed = rand_uniform_embedding_layer(postag_input, \n",
        "                                            len(index2postag), \n",
        "                                            postag_dim,\n",
        "                                            window*2+1, \n",
        "                                            'word_postag')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IeD7MTzCvaM"
      },
      "source": [
        "### BiLSTM Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL0_5lrNB9CL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273cff97-3dbb-4eae-d324-db727b3e07af"
      },
      "source": [
        "word_encoded = concatenate([twitter_embed, postag_embed], axis=2)\n",
        "word_encoded = Bidirectional(LSTM(100, \n",
        "                                  return_sequences=False, \n",
        "                                  dropout=0.2, \n",
        "                                  recurrent_dropout=0.2), \n",
        "                             name='word_encoded_blstm')(word_encoded)\n",
        "word_encoded = Dropout(0.5, name='word_encoded_blstm_dropout')(word_encoded)\n",
        "word_encoder = Model(inputs=[twitter_input, \n",
        "                             postag_input, \n",
        "                             ], outputs=[word_encoded])\n",
        "word_encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "word_twitter_input (InputLayer) [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_postag_input (InputLayer)  [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_twitter_embed (Embedding)  (None, 3, 400)       6066400     word_twitter_input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "word_postag_embed (Embedding)   (None, 3, 100)       10200       word_postag_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "word_twitter_embed_dropout (Dro (None, 3, 400)       0           word_twitter_embed[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "word_postag_embed_dropout (Drop (None, 3, 100)       0           word_postag_embed[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 500)       0           word_twitter_embed_dropout[0][0] \n",
            "                                                                 word_postag_embed_dropout[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "word_encoded_blstm (Bidirection (None, 200)          480800      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "word_encoded_blstm_dropout (Dro (None, 200)          0           word_encoded_blstm[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 6,557,400\n",
            "Trainable params: 480,800\n",
            "Non-trainable params: 6,076,600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_zDo-BAJ44J"
      },
      "source": [
        "### Feed-Forward NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1duUypbDJ983"
      },
      "source": [
        "gazetteer_input = get_input_layer((window * 2 + 1,), 'gazzetteer')\n",
        "gazetteer_embed = pretrained_embedding_layer(gaze_embeddings, \n",
        "                                             gazetteer_input, \n",
        "                                             window*2+1, \n",
        "                                             'gazetteer')\n",
        "gazetteer_dense = Dense(units=32, activation=\"relu\", name='gazetteer_dense')(gazetteer_embed)\n",
        "gazetteer_dense = Flatten()(gazetteer_embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTC3dcnJDJNh"
      },
      "source": [
        "### Build a NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBUZpFTdCzxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "330319a1-8956-4846-bd9c-b4d144c2ae8d"
      },
      "source": [
        "# Concatenate gazetteer_dense, char_encoded, word_encoded\n",
        "network = concatenate([gazetteer_dense, char_encoded, word_encoded], name='concat_layer')\n",
        "network = Dense(100, activation='relu', name='common_dense_layer') (network)\n",
        "\n",
        "seg_output = Dense(1, activation='sigmoid', name='seg_output')(network)\n",
        "cat_output = Dense(len(index2label_cat), activation='softmax', name='cat_output')(network)\n",
        "\n",
        "word_inputs = [twitter_input, postag_input]\n",
        "char_inputs = [char_ortho_input]\n",
        "other_input = [gazetteer_input]\n",
        "\n",
        "model = Model(inputs=other_input + char_inputs + word_inputs, \n",
        "              outputs=[seg_output, cat_output], \n",
        "              name='ne_model')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ne_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_ortho_input (InputLayer)   [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_ortho_embed (Embedding)    (None, 20, 30)       150         char_ortho_input[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "word_twitter_input (InputLayer) [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_postag_input (InputLayer)  [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_ortho_embed_dropout (Dropo (None, 20, 30)       0           char_ortho_embed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "word_twitter_embed (Embedding)  (None, 3, 400)       6066400     word_twitter_input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "word_postag_embed (Embedding)   (None, 3, 100)       10200       word_postag_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gazzetteer_input (InputLayer)   [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 18, 64)       5824        char_ortho_embed_dropout[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "word_twitter_embed_dropout (Dro (None, 3, 400)       0           word_twitter_embed[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "word_postag_embed_dropout (Drop (None, 3, 100)       0           word_postag_embed[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gazetteer_embed (Embedding)     (None, 3, 6)         115986      gazzetteer_input[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 16, 64)       12352       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 500)       0           word_twitter_embed_dropout[0][0] \n",
            "                                                                 word_postag_embed_dropout[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "gazetteer_embed_dropout (Dropou (None, 3, 6)         0           gazetteer_embed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 64)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "word_encoded_blstm (Bidirection (None, 200)          480800      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 18)           0           gazetteer_embed_dropout[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "char_encoded_dense (Dense)      (None, 32)           2080        global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "word_encoded_blstm_dropout (Dro (None, 200)          0           word_encoded_blstm[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, 250)          0           flatten[0][0]                    \n",
            "                                                                 char_encoded_dense[0][0]         \n",
            "                                                                 word_encoded_blstm_dropout[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "common_dense_layer (Dense)      (None, 100)          25100       concat_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "seg_output (Dense)              (None, 1)            101         common_dense_layer[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "cat_output (Dense)              (None, 13)           1313        common_dense_layer[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 6,720,306\n",
            "Trainable params: 527,570\n",
            "Non-trainable params: 6,192,736\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUVS35vNyUc"
      },
      "source": [
        "# Change dtype from float32 to int64\n",
        "y_cat_train = y_cat_train.astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ky1UdrDdyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcfc5ae-6c48-4fe0-d584-8e609321a7d6"
      },
      "source": [
        "adamax = Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "model.compile(optimizer=adamax,\n",
        "              loss={'seg_output': 'binary_crossentropy', \n",
        "                    'cat_output': 'categorical_crossentropy'},\n",
        "              loss_weights={'seg_output': 1., \n",
        "                            'cat_output': 1.},\n",
        "              metrics={'seg_output': ['accuracy'],\n",
        "                       'cat_output': ['accuracy']})\n",
        "\n",
        "early_stopping = EarlyStopping(patience=20, verbose=1)\n",
        "# checkpointer = ModelCheckpoint(filepath='{}weights/{}.hdf5'.format(WEIGHTS_DIR, experiment),\n",
        "#                                save_best_only=True, verbose=1)\n",
        "train_word_values = [x_word_twitter_train, x_postag_train]\n",
        "train_char_values = [x_ortho_twitter_train]\n",
        "train_other_values = [x_gaze_train]\n",
        "\n",
        "hist = model.fit(train_other_values + train_char_values + train_word_values, \n",
        "                 {'seg_output': y_seg_train, 'cat_output': y_cat_train}, \n",
        "                 batch_size=500, \n",
        "                 epochs=150, \n",
        "                 verbose=1, \n",
        "                 shuffle=True,\n",
        "                 validation_split=0.2,\n",
        "                 callbacks=[early_stopping])           # , checkpointer])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "126/126 [==============================] - 66s 56ms/step - loss: 1.1979 - seg_output_loss: 0.3063 - cat_output_loss: 0.8915 - seg_output_accuracy: 0.9259 - cat_output_accuracy: 0.8511 - val_loss: 0.5959 - val_seg_output_loss: 0.2085 - val_cat_output_loss: 0.3873 - val_seg_output_accuracy: 0.9203 - val_cat_output_accuracy: 0.9205\n",
            "Epoch 2/150\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.3996 - seg_output_loss: 0.1390 - cat_output_loss: 0.2605 - seg_output_accuracy: 0.9501 - cat_output_accuracy: 0.9506 - val_loss: 0.5364 - val_seg_output_loss: 0.1829 - val_cat_output_loss: 0.3534 - val_seg_output_accuracy: 0.9269 - val_cat_output_accuracy: 0.9207\n",
            "Epoch 3/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.3560 - seg_output_loss: 0.1203 - cat_output_loss: 0.2357 - seg_output_accuracy: 0.9541 - cat_output_accuracy: 0.9491 - val_loss: 0.4953 - val_seg_output_loss: 0.1658 - val_cat_output_loss: 0.3295 - val_seg_output_accuracy: 0.9342 - val_cat_output_accuracy: 0.9223\n",
            "Epoch 4/150\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.3192 - seg_output_loss: 0.1067 - cat_output_loss: 0.2124 - seg_output_accuracy: 0.9601 - cat_output_accuracy: 0.9525 - val_loss: 0.4630 - val_seg_output_loss: 0.1526 - val_cat_output_loss: 0.3104 - val_seg_output_accuracy: 0.9432 - val_cat_output_accuracy: 0.9266\n",
            "Epoch 5/150\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.2935 - seg_output_loss: 0.0967 - cat_output_loss: 0.1969 - seg_output_accuracy: 0.9642 - cat_output_accuracy: 0.9550 - val_loss: 0.4114 - val_seg_output_loss: 0.1310 - val_cat_output_loss: 0.2804 - val_seg_output_accuracy: 0.9564 - val_cat_output_accuracy: 0.9383\n",
            "Epoch 6/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.2806 - seg_output_loss: 0.0915 - cat_output_loss: 0.1891 - seg_output_accuracy: 0.9669 - cat_output_accuracy: 0.9567 - val_loss: 0.3970 - val_seg_output_loss: 0.1271 - val_cat_output_loss: 0.2699 - val_seg_output_accuracy: 0.9572 - val_cat_output_accuracy: 0.9407\n",
            "Epoch 7/150\n",
            "126/126 [==============================] - 5s 40ms/step - loss: 0.2607 - seg_output_loss: 0.0855 - cat_output_loss: 0.1753 - seg_output_accuracy: 0.9698 - cat_output_accuracy: 0.9598 - val_loss: 0.3916 - val_seg_output_loss: 0.1275 - val_cat_output_loss: 0.2641 - val_seg_output_accuracy: 0.9567 - val_cat_output_accuracy: 0.9411\n",
            "Epoch 8/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.2562 - seg_output_loss: 0.0841 - cat_output_loss: 0.1720 - seg_output_accuracy: 0.9700 - cat_output_accuracy: 0.9595 - val_loss: 0.3850 - val_seg_output_loss: 0.1264 - val_cat_output_loss: 0.2586 - val_seg_output_accuracy: 0.9580 - val_cat_output_accuracy: 0.9423\n",
            "Epoch 9/150\n",
            "126/126 [==============================] - 5s 40ms/step - loss: 0.2451 - seg_output_loss: 0.0816 - cat_output_loss: 0.1635 - seg_output_accuracy: 0.9706 - cat_output_accuracy: 0.9610 - val_loss: 0.3677 - val_seg_output_loss: 0.1195 - val_cat_output_loss: 0.2481 - val_seg_output_accuracy: 0.9592 - val_cat_output_accuracy: 0.9428\n",
            "Epoch 10/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.2440 - seg_output_loss: 0.0828 - cat_output_loss: 0.1612 - seg_output_accuracy: 0.9704 - cat_output_accuracy: 0.9618 - val_loss: 0.3676 - val_seg_output_loss: 0.1211 - val_cat_output_loss: 0.2465 - val_seg_output_accuracy: 0.9593 - val_cat_output_accuracy: 0.9431\n",
            "Epoch 11/150\n",
            "126/126 [==============================] - 5s 40ms/step - loss: 0.2368 - seg_output_loss: 0.0804 - cat_output_loss: 0.1564 - seg_output_accuracy: 0.9714 - cat_output_accuracy: 0.9622 - val_loss: 0.3523 - val_seg_output_loss: 0.1166 - val_cat_output_loss: 0.2356 - val_seg_output_accuracy: 0.9598 - val_cat_output_accuracy: 0.9448\n",
            "Epoch 12/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.2377 - seg_output_loss: 0.0809 - cat_output_loss: 0.1568 - seg_output_accuracy: 0.9705 - cat_output_accuracy: 0.9621 - val_loss: 0.3668 - val_seg_output_loss: 0.1253 - val_cat_output_loss: 0.2414 - val_seg_output_accuracy: 0.9589 - val_cat_output_accuracy: 0.9439\n",
            "Epoch 13/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.2204 - seg_output_loss: 0.0760 - cat_output_loss: 0.1444 - seg_output_accuracy: 0.9725 - cat_output_accuracy: 0.9641 - val_loss: 0.3609 - val_seg_output_loss: 0.1226 - val_cat_output_loss: 0.2382 - val_seg_output_accuracy: 0.9586 - val_cat_output_accuracy: 0.9439\n",
            "Epoch 14/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.2290 - seg_output_loss: 0.0785 - cat_output_loss: 0.1505 - seg_output_accuracy: 0.9716 - cat_output_accuracy: 0.9626 - val_loss: 0.3474 - val_seg_output_loss: 0.1183 - val_cat_output_loss: 0.2291 - val_seg_output_accuracy: 0.9591 - val_cat_output_accuracy: 0.9451\n",
            "Epoch 15/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.2216 - seg_output_loss: 0.0758 - cat_output_loss: 0.1458 - seg_output_accuracy: 0.9737 - cat_output_accuracy: 0.9642 - val_loss: 0.3547 - val_seg_output_loss: 0.1230 - val_cat_output_loss: 0.2317 - val_seg_output_accuracy: 0.9589 - val_cat_output_accuracy: 0.9451\n",
            "Epoch 16/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.2290 - seg_output_loss: 0.0805 - cat_output_loss: 0.1485 - seg_output_accuracy: 0.9709 - cat_output_accuracy: 0.9634 - val_loss: 0.3489 - val_seg_output_loss: 0.1218 - val_cat_output_loss: 0.2271 - val_seg_output_accuracy: 0.9590 - val_cat_output_accuracy: 0.9456\n",
            "Epoch 17/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.2207 - seg_output_loss: 0.0783 - cat_output_loss: 0.1424 - seg_output_accuracy: 0.9712 - cat_output_accuracy: 0.9648 - val_loss: 0.3470 - val_seg_output_loss: 0.1214 - val_cat_output_loss: 0.2255 - val_seg_output_accuracy: 0.9588 - val_cat_output_accuracy: 0.9455\n",
            "Epoch 18/150\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.2160 - seg_output_loss: 0.0762 - cat_output_loss: 0.1398 - seg_output_accuracy: 0.9726 - cat_output_accuracy: 0.9652 - val_loss: 0.3456 - val_seg_output_loss: 0.1216 - val_cat_output_loss: 0.2241 - val_seg_output_accuracy: 0.9590 - val_cat_output_accuracy: 0.9465\n",
            "Epoch 19/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.2128 - seg_output_loss: 0.0756 - cat_output_loss: 0.1373 - seg_output_accuracy: 0.9725 - cat_output_accuracy: 0.9658 - val_loss: 0.3436 - val_seg_output_loss: 0.1209 - val_cat_output_loss: 0.2227 - val_seg_output_accuracy: 0.9590 - val_cat_output_accuracy: 0.9455\n",
            "Epoch 20/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.2132 - seg_output_loss: 0.0750 - cat_output_loss: 0.1382 - seg_output_accuracy: 0.9729 - cat_output_accuracy: 0.9654 - val_loss: 0.3453 - val_seg_output_loss: 0.1221 - val_cat_output_loss: 0.2233 - val_seg_output_accuracy: 0.9589 - val_cat_output_accuracy: 0.9453\n",
            "Epoch 21/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.2083 - seg_output_loss: 0.0736 - cat_output_loss: 0.1347 - seg_output_accuracy: 0.9736 - cat_output_accuracy: 0.9656 - val_loss: 0.3482 - val_seg_output_loss: 0.1230 - val_cat_output_loss: 0.2252 - val_seg_output_accuracy: 0.9586 - val_cat_output_accuracy: 0.9456\n",
            "Epoch 22/150\n",
            "126/126 [==============================] - 5s 40ms/step - loss: 0.2030 - seg_output_loss: 0.0715 - cat_output_loss: 0.1315 - seg_output_accuracy: 0.9738 - cat_output_accuracy: 0.9659 - val_loss: 0.3362 - val_seg_output_loss: 0.1169 - val_cat_output_loss: 0.2193 - val_seg_output_accuracy: 0.9599 - val_cat_output_accuracy: 0.9460\n",
            "Epoch 23/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.2051 - seg_output_loss: 0.0736 - cat_output_loss: 0.1315 - seg_output_accuracy: 0.9737 - cat_output_accuracy: 0.9657 - val_loss: 0.3333 - val_seg_output_loss: 0.1179 - val_cat_output_loss: 0.2154 - val_seg_output_accuracy: 0.9597 - val_cat_output_accuracy: 0.9465\n",
            "Epoch 24/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.2088 - seg_output_loss: 0.0746 - cat_output_loss: 0.1342 - seg_output_accuracy: 0.9727 - cat_output_accuracy: 0.9657 - val_loss: 0.3342 - val_seg_output_loss: 0.1185 - val_cat_output_loss: 0.2157 - val_seg_output_accuracy: 0.9603 - val_cat_output_accuracy: 0.9473\n",
            "Epoch 25/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.2030 - seg_output_loss: 0.0726 - cat_output_loss: 0.1304 - seg_output_accuracy: 0.9731 - cat_output_accuracy: 0.9658 - val_loss: 0.3427 - val_seg_output_loss: 0.1220 - val_cat_output_loss: 0.2207 - val_seg_output_accuracy: 0.9591 - val_cat_output_accuracy: 0.9462\n",
            "Epoch 26/150\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.1986 - seg_output_loss: 0.0716 - cat_output_loss: 0.1270 - seg_output_accuracy: 0.9741 - cat_output_accuracy: 0.9674 - val_loss: 0.3307 - val_seg_output_loss: 0.1168 - val_cat_output_loss: 0.2140 - val_seg_output_accuracy: 0.9600 - val_cat_output_accuracy: 0.9467\n",
            "Epoch 27/150\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.2101 - seg_output_loss: 0.0759 - cat_output_loss: 0.1342 - seg_output_accuracy: 0.9723 - cat_output_accuracy: 0.9653 - val_loss: 0.3311 - val_seg_output_loss: 0.1174 - val_cat_output_loss: 0.2137 - val_seg_output_accuracy: 0.9599 - val_cat_output_accuracy: 0.9465\n",
            "Epoch 28/150\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.1987 - seg_output_loss: 0.0719 - cat_output_loss: 0.1268 - seg_output_accuracy: 0.9731 - cat_output_accuracy: 0.9672 - val_loss: 0.3404 - val_seg_output_loss: 0.1218 - val_cat_output_loss: 0.2185 - val_seg_output_accuracy: 0.9599 - val_cat_output_accuracy: 0.9470\n",
            "Epoch 29/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.1974 - seg_output_loss: 0.0703 - cat_output_loss: 0.1271 - seg_output_accuracy: 0.9743 - cat_output_accuracy: 0.9663 - val_loss: 0.3341 - val_seg_output_loss: 0.1199 - val_cat_output_loss: 0.2142 - val_seg_output_accuracy: 0.9591 - val_cat_output_accuracy: 0.9470\n",
            "Epoch 30/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.1960 - seg_output_loss: 0.0716 - cat_output_loss: 0.1244 - seg_output_accuracy: 0.9735 - cat_output_accuracy: 0.9668 - val_loss: 0.3302 - val_seg_output_loss: 0.1177 - val_cat_output_loss: 0.2124 - val_seg_output_accuracy: 0.9598 - val_cat_output_accuracy: 0.9476\n",
            "Epoch 31/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.1940 - seg_output_loss: 0.0721 - cat_output_loss: 0.1219 - seg_output_accuracy: 0.9741 - cat_output_accuracy: 0.9689 - val_loss: 0.3371 - val_seg_output_loss: 0.1214 - val_cat_output_loss: 0.2157 - val_seg_output_accuracy: 0.9595 - val_cat_output_accuracy: 0.9470\n",
            "Epoch 32/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.1956 - seg_output_loss: 0.0713 - cat_output_loss: 0.1243 - seg_output_accuracy: 0.9741 - cat_output_accuracy: 0.9672 - val_loss: 0.3281 - val_seg_output_loss: 0.1166 - val_cat_output_loss: 0.2115 - val_seg_output_accuracy: 0.9609 - val_cat_output_accuracy: 0.9476\n",
            "Epoch 33/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.2014 - seg_output_loss: 0.0742 - cat_output_loss: 0.1272 - seg_output_accuracy: 0.9734 - cat_output_accuracy: 0.9671 - val_loss: 0.3253 - val_seg_output_loss: 0.1158 - val_cat_output_loss: 0.2095 - val_seg_output_accuracy: 0.9613 - val_cat_output_accuracy: 0.9476\n",
            "Epoch 34/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1906 - seg_output_loss: 0.0698 - cat_output_loss: 0.1208 - seg_output_accuracy: 0.9742 - cat_output_accuracy: 0.9681 - val_loss: 0.3271 - val_seg_output_loss: 0.1164 - val_cat_output_loss: 0.2107 - val_seg_output_accuracy: 0.9606 - val_cat_output_accuracy: 0.9473\n",
            "Epoch 35/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1880 - seg_output_loss: 0.0688 - cat_output_loss: 0.1192 - seg_output_accuracy: 0.9749 - cat_output_accuracy: 0.9687 - val_loss: 0.3205 - val_seg_output_loss: 0.1143 - val_cat_output_loss: 0.2062 - val_seg_output_accuracy: 0.9614 - val_cat_output_accuracy: 0.9485\n",
            "Epoch 36/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1890 - seg_output_loss: 0.0698 - cat_output_loss: 0.1192 - seg_output_accuracy: 0.9742 - cat_output_accuracy: 0.9681 - val_loss: 0.3141 - val_seg_output_loss: 0.1120 - val_cat_output_loss: 0.2020 - val_seg_output_accuracy: 0.9616 - val_cat_output_accuracy: 0.9488\n",
            "Epoch 37/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1872 - seg_output_loss: 0.0702 - cat_output_loss: 0.1170 - seg_output_accuracy: 0.9744 - cat_output_accuracy: 0.9689 - val_loss: 0.3290 - val_seg_output_loss: 0.1183 - val_cat_output_loss: 0.2107 - val_seg_output_accuracy: 0.9612 - val_cat_output_accuracy: 0.9483\n",
            "Epoch 38/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1836 - seg_output_loss: 0.0679 - cat_output_loss: 0.1157 - seg_output_accuracy: 0.9751 - cat_output_accuracy: 0.9691 - val_loss: 0.3177 - val_seg_output_loss: 0.1135 - val_cat_output_loss: 0.2042 - val_seg_output_accuracy: 0.9614 - val_cat_output_accuracy: 0.9483\n",
            "Epoch 39/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.1823 - seg_output_loss: 0.0666 - cat_output_loss: 0.1157 - seg_output_accuracy: 0.9751 - cat_output_accuracy: 0.9693 - val_loss: 0.3132 - val_seg_output_loss: 0.1113 - val_cat_output_loss: 0.2019 - val_seg_output_accuracy: 0.9620 - val_cat_output_accuracy: 0.9487\n",
            "Epoch 40/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.1818 - seg_output_loss: 0.0664 - cat_output_loss: 0.1154 - seg_output_accuracy: 0.9750 - cat_output_accuracy: 0.9681 - val_loss: 0.3151 - val_seg_output_loss: 0.1119 - val_cat_output_loss: 0.2031 - val_seg_output_accuracy: 0.9616 - val_cat_output_accuracy: 0.9484\n",
            "Epoch 41/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.1836 - seg_output_loss: 0.0691 - cat_output_loss: 0.1145 - seg_output_accuracy: 0.9749 - cat_output_accuracy: 0.9697 - val_loss: 0.3262 - val_seg_output_loss: 0.1186 - val_cat_output_loss: 0.2076 - val_seg_output_accuracy: 0.9606 - val_cat_output_accuracy: 0.9483\n",
            "Epoch 42/150\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.1794 - seg_output_loss: 0.0667 - cat_output_loss: 0.1126 - seg_output_accuracy: 0.9754 - cat_output_accuracy: 0.9691 - val_loss: 0.3201 - val_seg_output_loss: 0.1140 - val_cat_output_loss: 0.2061 - val_seg_output_accuracy: 0.9614 - val_cat_output_accuracy: 0.9486\n",
            "Epoch 43/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.1812 - seg_output_loss: 0.0669 - cat_output_loss: 0.1143 - seg_output_accuracy: 0.9756 - cat_output_accuracy: 0.9693 - val_loss: 0.3206 - val_seg_output_loss: 0.1139 - val_cat_output_loss: 0.2066 - val_seg_output_accuracy: 0.9616 - val_cat_output_accuracy: 0.9484\n",
            "Epoch 44/150\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.1809 - seg_output_loss: 0.0660 - cat_output_loss: 0.1149 - seg_output_accuracy: 0.9763 - cat_output_accuracy: 0.9696 - val_loss: 0.3200 - val_seg_output_loss: 0.1148 - val_cat_output_loss: 0.2052 - val_seg_output_accuracy: 0.9616 - val_cat_output_accuracy: 0.9491\n",
            "Epoch 45/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.1803 - seg_output_loss: 0.0667 - cat_output_loss: 0.1135 - seg_output_accuracy: 0.9756 - cat_output_accuracy: 0.9692 - val_loss: 0.3202 - val_seg_output_loss: 0.1149 - val_cat_output_loss: 0.2052 - val_seg_output_accuracy: 0.9615 - val_cat_output_accuracy: 0.9485\n",
            "Epoch 46/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.1850 - seg_output_loss: 0.0690 - cat_output_loss: 0.1160 - seg_output_accuracy: 0.9749 - cat_output_accuracy: 0.9692 - val_loss: 0.3168 - val_seg_output_loss: 0.1121 - val_cat_output_loss: 0.2046 - val_seg_output_accuracy: 0.9618 - val_cat_output_accuracy: 0.9493\n",
            "Epoch 47/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1808 - seg_output_loss: 0.0681 - cat_output_loss: 0.1127 - seg_output_accuracy: 0.9763 - cat_output_accuracy: 0.9702 - val_loss: 0.3128 - val_seg_output_loss: 0.1110 - val_cat_output_loss: 0.2018 - val_seg_output_accuracy: 0.9622 - val_cat_output_accuracy: 0.9495\n",
            "Epoch 48/150\n",
            "126/126 [==============================] - 5s 42ms/step - loss: 0.1776 - seg_output_loss: 0.0667 - cat_output_loss: 0.1110 - seg_output_accuracy: 0.9760 - cat_output_accuracy: 0.9695 - val_loss: 0.3128 - val_seg_output_loss: 0.1120 - val_cat_output_loss: 0.2008 - val_seg_output_accuracy: 0.9620 - val_cat_output_accuracy: 0.9494\n",
            "Epoch 49/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1730 - seg_output_loss: 0.0648 - cat_output_loss: 0.1082 - seg_output_accuracy: 0.9759 - cat_output_accuracy: 0.9702 - val_loss: 0.3330 - val_seg_output_loss: 0.1215 - val_cat_output_loss: 0.2115 - val_seg_output_accuracy: 0.9605 - val_cat_output_accuracy: 0.9488\n",
            "Epoch 50/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1767 - seg_output_loss: 0.0656 - cat_output_loss: 0.1111 - seg_output_accuracy: 0.9761 - cat_output_accuracy: 0.9695 - val_loss: 0.3215 - val_seg_output_loss: 0.1161 - val_cat_output_loss: 0.2054 - val_seg_output_accuracy: 0.9614 - val_cat_output_accuracy: 0.9494\n",
            "Epoch 51/150\n",
            "126/126 [==============================] - 5s 40ms/step - loss: 0.1684 - seg_output_loss: 0.0628 - cat_output_loss: 0.1056 - seg_output_accuracy: 0.9768 - cat_output_accuracy: 0.9716 - val_loss: 0.3208 - val_seg_output_loss: 0.1147 - val_cat_output_loss: 0.2061 - val_seg_output_accuracy: 0.9625 - val_cat_output_accuracy: 0.9495\n",
            "Epoch 52/150\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.1722 - seg_output_loss: 0.0640 - cat_output_loss: 0.1083 - seg_output_accuracy: 0.9760 - cat_output_accuracy: 0.9703 - val_loss: 0.3185 - val_seg_output_loss: 0.1159 - val_cat_output_loss: 0.2026 - val_seg_output_accuracy: 0.9616 - val_cat_output_accuracy: 0.9497\n",
            "Epoch 53/150\n",
            "126/126 [==============================] - 5s 42ms/step - loss: 0.1696 - seg_output_loss: 0.0636 - cat_output_loss: 0.1060 - seg_output_accuracy: 0.9769 - cat_output_accuracy: 0.9706 - val_loss: 0.3133 - val_seg_output_loss: 0.1120 - val_cat_output_loss: 0.2013 - val_seg_output_accuracy: 0.9620 - val_cat_output_accuracy: 0.9497\n",
            "Epoch 54/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1717 - seg_output_loss: 0.0645 - cat_output_loss: 0.1072 - seg_output_accuracy: 0.9761 - cat_output_accuracy: 0.9702 - val_loss: 0.3236 - val_seg_output_loss: 0.1171 - val_cat_output_loss: 0.2065 - val_seg_output_accuracy: 0.9613 - val_cat_output_accuracy: 0.9488\n",
            "Epoch 55/150\n",
            "126/126 [==============================] - 5s 43ms/step - loss: 0.1679 - seg_output_loss: 0.0629 - cat_output_loss: 0.1051 - seg_output_accuracy: 0.9767 - cat_output_accuracy: 0.9708 - val_loss: 0.3147 - val_seg_output_loss: 0.1131 - val_cat_output_loss: 0.2016 - val_seg_output_accuracy: 0.9623 - val_cat_output_accuracy: 0.9498\n",
            "Epoch 56/150\n",
            "126/126 [==============================] - 5s 42ms/step - loss: 0.1696 - seg_output_loss: 0.0634 - cat_output_loss: 0.1063 - seg_output_accuracy: 0.9762 - cat_output_accuracy: 0.9701 - val_loss: 0.3149 - val_seg_output_loss: 0.1129 - val_cat_output_loss: 0.2019 - val_seg_output_accuracy: 0.9617 - val_cat_output_accuracy: 0.9495\n",
            "Epoch 57/150\n",
            "126/126 [==============================] - 5s 42ms/step - loss: 0.1711 - seg_output_loss: 0.0639 - cat_output_loss: 0.1072 - seg_output_accuracy: 0.9763 - cat_output_accuracy: 0.9705 - val_loss: 0.3204 - val_seg_output_loss: 0.1168 - val_cat_output_loss: 0.2037 - val_seg_output_accuracy: 0.9614 - val_cat_output_accuracy: 0.9500\n",
            "Epoch 58/150\n",
            "126/126 [==============================] - 5s 40ms/step - loss: 0.1645 - seg_output_loss: 0.0613 - cat_output_loss: 0.1033 - seg_output_accuracy: 0.9769 - cat_output_accuracy: 0.9706 - val_loss: 0.3236 - val_seg_output_loss: 0.1157 - val_cat_output_loss: 0.2079 - val_seg_output_accuracy: 0.9623 - val_cat_output_accuracy: 0.9493\n",
            "Epoch 59/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.1654 - seg_output_loss: 0.0615 - cat_output_loss: 0.1039 - seg_output_accuracy: 0.9780 - cat_output_accuracy: 0.9716 - val_loss: 0.3132 - val_seg_output_loss: 0.1111 - val_cat_output_loss: 0.2022 - val_seg_output_accuracy: 0.9634 - val_cat_output_accuracy: 0.9498\n",
            "Epoch 60/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.1633 - seg_output_loss: 0.0620 - cat_output_loss: 0.1013 - seg_output_accuracy: 0.9776 - cat_output_accuracy: 0.9714 - val_loss: 0.3289 - val_seg_output_loss: 0.1190 - val_cat_output_loss: 0.2100 - val_seg_output_accuracy: 0.9618 - val_cat_output_accuracy: 0.9493\n",
            "Epoch 61/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.1652 - seg_output_loss: 0.0625 - cat_output_loss: 0.1027 - seg_output_accuracy: 0.9773 - cat_output_accuracy: 0.9715 - val_loss: 0.3227 - val_seg_output_loss: 0.1166 - val_cat_output_loss: 0.2061 - val_seg_output_accuracy: 0.9617 - val_cat_output_accuracy: 0.9504\n",
            "Epoch 62/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.1633 - seg_output_loss: 0.0611 - cat_output_loss: 0.1022 - seg_output_accuracy: 0.9778 - cat_output_accuracy: 0.9725 - val_loss: 0.3217 - val_seg_output_loss: 0.1168 - val_cat_output_loss: 0.2049 - val_seg_output_accuracy: 0.9614 - val_cat_output_accuracy: 0.9497\n",
            "Epoch 63/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.1644 - seg_output_loss: 0.0613 - cat_output_loss: 0.1031 - seg_output_accuracy: 0.9776 - cat_output_accuracy: 0.9706 - val_loss: 0.3299 - val_seg_output_loss: 0.1210 - val_cat_output_loss: 0.2089 - val_seg_output_accuracy: 0.9607 - val_cat_output_accuracy: 0.9496\n",
            "Epoch 64/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.1644 - seg_output_loss: 0.0625 - cat_output_loss: 0.1018 - seg_output_accuracy: 0.9770 - cat_output_accuracy: 0.9716 - val_loss: 0.3221 - val_seg_output_loss: 0.1161 - val_cat_output_loss: 0.2060 - val_seg_output_accuracy: 0.9620 - val_cat_output_accuracy: 0.9500\n",
            "Epoch 65/150\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.1640 - seg_output_loss: 0.0615 - cat_output_loss: 0.1024 - seg_output_accuracy: 0.9778 - cat_output_accuracy: 0.9716 - val_loss: 0.3268 - val_seg_output_loss: 0.1189 - val_cat_output_loss: 0.2079 - val_seg_output_accuracy: 0.9617 - val_cat_output_accuracy: 0.9499\n",
            "Epoch 66/150\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.1626 - seg_output_loss: 0.0612 - cat_output_loss: 0.1013 - seg_output_accuracy: 0.9775 - cat_output_accuracy: 0.9718 - val_loss: 0.3271 - val_seg_output_loss: 0.1183 - val_cat_output_loss: 0.2088 - val_seg_output_accuracy: 0.9616 - val_cat_output_accuracy: 0.9497\n",
            "Epoch 67/150\n",
            "126/126 [==============================] - 5s 42ms/step - loss: 0.1589 - seg_output_loss: 0.0608 - cat_output_loss: 0.0982 - seg_output_accuracy: 0.9779 - cat_output_accuracy: 0.9720 - val_loss: 0.3301 - val_seg_output_loss: 0.1198 - val_cat_output_loss: 0.2103 - val_seg_output_accuracy: 0.9617 - val_cat_output_accuracy: 0.9495\n",
            "Epoch 68/150\n",
            "126/126 [==============================] - 5s 42ms/step - loss: 0.1647 - seg_output_loss: 0.0623 - cat_output_loss: 0.1024 - seg_output_accuracy: 0.9777 - cat_output_accuracy: 0.9715 - val_loss: 0.3294 - val_seg_output_loss: 0.1201 - val_cat_output_loss: 0.2092 - val_seg_output_accuracy: 0.9609 - val_cat_output_accuracy: 0.9501\n",
            "Epoch 00068: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SPdOxxCD3fj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "28485ae7-e128-4ee7-fe5b-33f7711585af"
      },
      "source": [
        "# Plot train & validation loss\n",
        "train_loss = hist.history[\"loss\"]\n",
        "val_loss = hist.history[\"val_loss\"]\n",
        "plt.plot(range(len(train_loss)), train_loss, color=\"red\", label=\"Train Loss\")\n",
        "plt.plot(range(len(train_loss)), val_loss, color=\"blue\", label=\"Validation Loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq2DtMw4EEP_"
      },
      "source": [
        "### Neural Network Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLOiKeA7EHPJ"
      },
      "source": [
        "cat_model = Model(inputs=other_input + char_inputs + word_inputs, \n",
        "                  outputs=[cat_output], \n",
        "                  name='cat_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjcgoGq0EYAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d1b882-7600-4dbe-d12b-62afb008722e"
      },
      "source": [
        "# Predicting test data\n",
        "test_word_values = [x_word_twitter_test, x_postag_test]\n",
        "test_char_values = [x_ortho_twitter_test]\n",
        "test_other_values = [x_gaze_test]\n",
        "\n",
        "prediction_probs = cat_model.predict(test_other_values + \n",
        "                                     test_char_values + \n",
        "                                     test_word_values, batch_size=500, verbose=1)\n",
        "# Decoding predictions\n",
        "decoded_predictions = utils.decode_predictions([np.argmax(p) for p in prediction_probs], index2label_cat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 2s 7ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fra2rTgEmKv"
      },
      "source": [
        "original_test_tweets,_ = utils.read_file_as_lists(TEST)\n",
        "\n",
        "assert len(original_test_tweets) == len(tweets_test)\n",
        "assert len(utils.flatten(original_test_tweets)) == len(utils.flatten(tweets_test))\n",
        "assert len(utils.flatten(original_test_tweets)) == len(decoded_predictions)\n",
        "    \n",
        "utils.save_final_predictions('{}{}.network.tsv'.format(PREDICTIONS_DIR, experiment), \n",
        "                             original_test_tweets,\n",
        "                             decoded_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKR8ya9hEoFA"
      },
      "source": [
        "### NN Predection insights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFjBH0P5EtnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca2b3b4-bd77-480b-e82d-c9e2b572ce14"
      },
      "source": [
        "print(\"Classification Report\\n\")\n",
        "print(classification_report(utils.flatten(labels_test), decoded_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "  B-corporation       0.20      0.12      0.15        66\n",
            "B-creative-work       0.65      0.11      0.18       142\n",
            "        B-group       0.59      0.14      0.23       165\n",
            "     B-location       0.42      0.58      0.48       150\n",
            "       B-person       0.74      0.52      0.61       429\n",
            "      B-product       0.66      0.17      0.26       127\n",
            "  I-corporation       1.00      0.05      0.09        22\n",
            "I-creative-work       0.61      0.05      0.09       218\n",
            "        I-group       0.41      0.10      0.16        70\n",
            "     I-location       0.60      0.27      0.37        94\n",
            "       I-person       0.77      0.55      0.64       131\n",
            "      I-product       0.56      0.15      0.24       126\n",
            "              O       0.95      0.99      0.97     21654\n",
            "\n",
            "       accuracy                           0.94     23394\n",
            "      macro avg       0.63      0.29      0.34     23394\n",
            "   weighted avg       0.93      0.94      0.93     23394\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRVWsXzpE8oR"
      },
      "source": [
        "### CRF-Suite Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_ilsBxhE9_Q"
      },
      "source": [
        "nn_model = Model(inputs=model.input, outputs=model.get_layer('common_dense_layer').output)\n",
        "\n",
        "def get_xseq(model, matrix):\n",
        "    xseq = [{'feat{}'.format(i):float(w) for i,w in enumerate(list(features))} \n",
        "            for features \n",
        "            in model.predict(matrix)]\n",
        "    return ItemSequence(xseq)\n",
        "\n",
        "xseq_train = get_xseq(nn_model, train_other_values + train_char_values + train_word_values)\n",
        "yseq_train = utils.flatten(labels_train)\n",
        "\n",
        "trainer = crf.Trainer(verbose=False)\n",
        "trainer.append(xseq_train, yseq_train)\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,                           # L1 penalty\n",
        "    'c2': 1e-3,                          # L2 penalty\n",
        "    'max_iterations': 100,               # stop earlier\n",
        "    'feature.possible_transitions': True # possible transitions, but not observed\n",
        "})\n",
        "trainer.train('{}.pycrfsuite'.format(experiment))\n",
        "trainer.logparser.last_iteration\n",
        "\n",
        "tagger = crf.Tagger()\n",
        "tagger.open('{}.pycrfsuite'.format(experiment))\n",
        "\n",
        "# Predicting test data\n",
        "decoded_predictions_crf = tagger.tag(get_xseq(nn_model, \n",
        "                                          test_other_values + \n",
        "                                          test_char_values + \n",
        "                                          test_word_values))\n",
        "\n",
        "# Saving predictions\n",
        "utils.save_final_predictions('{}{}.crfsuite.tsv'.format(PREDICTIONS_DIR, experiment), \n",
        "                             original_test_tweets,\n",
        "                             decoded_predictions_crf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txco8F5YFTSB"
      },
      "source": [
        "### CRF Prediction insigths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PN4Uk_DFVWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb21147-e8df-4209-d9f9-6564ef4ab923"
      },
      "source": [
        "print(\"Classification Report\\n\")\n",
        "print(classification_report(utils.flatten(labels_test), decoded_predictions_crf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "  B-corporation       0.36      0.24      0.29        66\n",
            "B-creative-work       0.49      0.15      0.23       142\n",
            "        B-group       0.48      0.20      0.28       165\n",
            "     B-location       0.55      0.51      0.53       150\n",
            "       B-person       0.74      0.51      0.60       429\n",
            "      B-product       0.71      0.19      0.30       127\n",
            "  I-corporation       0.50      0.14      0.21        22\n",
            "I-creative-work       0.46      0.14      0.22       218\n",
            "        I-group       0.38      0.21      0.28        70\n",
            "     I-location       0.56      0.21      0.31        94\n",
            "       I-person       0.79      0.54      0.64       131\n",
            "      I-product       0.56      0.34      0.42       126\n",
            "              O       0.96      0.99      0.97     21654\n",
            "\n",
            "       accuracy                           0.94     23394\n",
            "      macro avg       0.58      0.34      0.41     23394\n",
            "   weighted avg       0.93      0.94      0.93     23394\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLyQTGs2QraV"
      },
      "source": [
        "### Save the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z73b2-MwUdA4"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5UTyrQtQwEN"
      },
      "source": [
        "df = pd.DataFrame(utils.flatten(labels_test), columns=['true_labels'])\n",
        "df['nn_predictions'] = decoded_predictions\n",
        "df['crf_predictions'] = decoded_predictions_crf\n",
        "df.to_csv('multi_task_results.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB24MFbhQ5ji"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}